{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam/ham classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will train a classifier to recognise spam emails. The data was taken from this [enron spam](https://www.kaggle.com/wanderfj/enron-spam)  kaggle dataset. The dataset is described [here](https://www.researchgate.net/publication/221650814_Spam_Filtering_with_Naive_Bayes_-_Which_Naive_Bayes). This will familiarize you with tools  for text analysis  from  the scikit-learn library. \n",
    "\n",
    "The data is provided as a zip archive \"enron_spam.zip\". You can unpack it with command `unzip enron_spam.zip` which will create a directory `data`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data  consists of 6 batches of emails. Each batch corresponds to different person and different spam source. Each batch is stored in different subdirectory of `data` named `Enron_1` to `Enron_6`. Each email is stored in separate file :( Spam and ham emails are stored in different subdirectories. Fortunatelly the scikit-learn library provides a functiona `load_files` that can read data in this format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL LIBRARIES NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load data from given batch using the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "data1 = load_files('enron_spam/data/Enron_1/', encoding='latin-1', shuffle=True, categories=['ham', 'spam'] )\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns a python dictionary. The entry 'data' contains the data from files and the entry 'target' contains the labels assigned according to the subdirectory names. The labels are integers and corresponding names can be found in the entry 'target_names'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4137"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Subject: re : cornhusker deal\\r\\nrita ,\\r\\nthings have been changing daily on this thing , so we were waiting to get it\\r\\nall figured out .\\r\\ni did tell mark mccoy to handle this , and he is going to get you all the\\r\\ninformation right after\\r\\nthe long weekend . hope this helps . pat\\r\\nrita wynne @ ect\\r\\n08 / 31 / 2000 05 : 25 pm\\r\\nto : pat clynes / corp / enron @ enron , daren j farmer / hou / ect @ ect\\r\\ncc :\\r\\nsubject : cornhusker deal\\r\\nhey guys ,\\r\\ni need to be bought up to speed on the cornhusker deal . i don ' t know what\\r\\nthe impact is to my group or what we should expect to see in terms of\\r\\nallocations or settlements . any info . either of you can provide would be\\r\\nappreciated . thanks and have a great holiday !\",\n",
       " 'Subject: enron / hpl actuals for sept . 18 , 2000\\r\\nls hpl lsk ic 2 . 500 / enron']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['data'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4137"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['target'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham', 'spam']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train the multinomial bayes classifier using scikit-learn  for the first batch of data in data/Enron_1 as described in text_analysis notebook.\n",
    "    1. Set asside 20% of data for testings and train the multinomial bayes classifier using the remaining 80% of data.This requires  transforming the data to feature vectors using CountVectoriser  from scikit-learn. How big is the resulting vocabulary ? \n",
    "    1. Using the test set \n",
    "        1. Draw the confusion matrix using `plot_confusion_matrix` from scikit-learn (see the latest update of the text_analysis notebook) using the test set. \n",
    "        1. Calculate recall and precision scores. \n",
    "        1. Draw the ROC curve and calculate the AUC score  using the test set. \n",
    "        1. What percentage of valid mails is classified as spam?\n",
    "        1. Assuming that only mails classified as ham are put in our mailbox what percentage of mail in our inbox is spam?\n",
    "        \n",
    "    1. Find ten most probable and least probable words for each class.     \n",
    "    1. Check the classifier on the remaining datasets data/Enron_2-6. For each set calculate recall and precision. \n",
    "    1. Combine all sets.  Train a new classifier on the combined  set, of course after dividing into test and train sets. Redo point B. using this classifier and combined test set. \n",
    "    1. Assumimg that we want to keep the frequency of misclassified ham mails belowe 5 per file, what would be the percentage of spam in our inbox?\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hint__ You can create a dataframe from the data using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'text': data1['data'], 'spam': data1['target']})\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2937\n",
       "1    1200\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: re : cornhusker deal\\r\\nrita ,\\r\\nthi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: enron / hpl actuals for sept . 18 , 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: fw : teco / frontera financial trades...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: jan . 01 sale to texas general land o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : volume increase - hpl meter 68 -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject: re : koch midstream services co\\r\\nti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject: hpl meter # 981525 texoma d / p - gsu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject: buy office xp for fifty bucks percent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: re : cornhusker deal\\r\\nrita ,\\r\\nthi...     0\n",
       "1  Subject: enron / hpl actuals for sept . 18 , 2...     0\n",
       "2  Subject: fw : teco / frontera financial trades...     0\n",
       "3  Subject: jan . 01 sale to texas general land o...     0\n",
       "4  Subject: re : volume increase - hpl meter 68 -...     0\n",
       "5  Subject: re : koch midstream services co\\r\\nti...     0\n",
       "6  Subject: hpl meter # 981525 texoma d / p - gsu...     0\n",
       "7  Subject: buy office xp for fifty bucks percent...     1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4137"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART: A\n",
    "#Set asside 20% of data for testings and train the multinomial bayes classifier using the remaining 80% of data.\n",
    "#This requires transforming the data to feature vectors using CountVectoriser from scikit-learn.\n",
    "#How big is the resulting vocabulary ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set aside 20% of data for testing!\n",
    "seed = 57576\n",
    "train_data, test_data = train_test_split(df1,train_size=0.8, test_size=0.2, stratify=df1['spam'], random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2349\n",
       "1     960\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    588\n",
       "1    240\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB() accuracy score:\n",
      "0.9794685990338164\n",
      "\n",
      "Leangth of the created vocabulary:\n",
      "37931\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_spam_score = vectorizer.fit_transform(train_data.text)\n",
    "test_spam_score = vectorizer.transform(test_data.text)\n",
    "\n",
    "#Multinomial Bayes classification\n",
    "base_spam_classifier = MultinomialNB()\n",
    "base_spam_classifier.fit(train_spam_score, train_data.spam)\n",
    "\n",
    "#Accuracy score of MultinomialNB() classifier\n",
    "print(\"MultinomialNB() accuracy score:\")\n",
    "base_predicted = base_spam_classifier.predict(test_spam_score)\n",
    "base_predicted_proba = base_spam_classifier.predict_proba(test_spam_score)\n",
    "\n",
    "print(accuracy_score(test_data.spam, base_predicted))\n",
    "\n",
    "#Print vocabulaty size\n",
    "print(\"\\nLeangth of the created vocabulary:\")\n",
    "print(len(vectorizer.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART: B\n",
    "#Using the test set:\n",
    "\n",
    "#a). Draw the confusion matrix using plot_confusion_matrix from scikit-learn\n",
    "#(see the latest update of the text_analysis notebook) using the test set.\n",
    "\n",
    "#b). Calculate recall and precision scores.\n",
    "\n",
    "#c). Draw the ROC curve and calculate the AUC score using the test set.\n",
    "\n",
    "#d). What percentage of valid mails is classified as spam?\n",
    "\n",
    "#e). Assuming that only mails classified as ham are put in our mailbox what percentage of mail\n",
    "#in our inbox is spam?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PART B a).Draw the confusion matrix using plot_confusion_matrix from scikit-learn\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "disp = plot_confusion_matrix(base_spam_classifier, test_spam_score, test_data.spam, normalize='true', ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.975623530414645\n",
      "recall score:    0.9744472789115646\n",
      "f1 score:        0.9750329470736081\n"
     ]
    }
   ],
   "source": [
    "#PART B b). Calculate recall and precision scores.\n",
    "print(\"precision score:\", precision_score(test_data.spam, base_predicted, average='macro'))\n",
    "print(\"recall score:   \", recall_score(test_data.spam, base_predicted, average='macro'))\n",
    "print(\"f1 score:       \", f1_score(test_data.spam, base_predicted, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----ROC----RECEIVER---OPERATOR---CHARACTERSTIC----\n",
      "\n",
      "When prob>threshold => return 1 else return 0.\n",
      "Prob tresholds:\n",
      " [2.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 9.99992336e-001\n",
      " 9.99992323e-001 9.98329240e-001 9.98265537e-001 9.71333110e-001\n",
      " 9.69931471e-001 9.39337019e-001 9.22071594e-001 6.43328048e-001\n",
      " 6.17304073e-001 3.79856517e-001 3.58025681e-001 2.49705762e-001\n",
      " 1.71478692e-001 1.52966761e-001 1.26585659e-001 6.06448975e-002\n",
      " 5.77389141e-002 7.53574958e-006 7.03037451e-006 1.24542679e-012\n",
      " 1.05988586e-012 9.46134283e-029 8.65004227e-029 3.72756772e-032\n",
      " 2.50257063e-032 1.43279037e-322 0.00000000e+000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----AUC----AREA---UNDER---CURVE-------------------\n",
      "\n",
      "0.996984835600907\n"
     ]
    }
   ],
   "source": [
    "#PART B c). Draw ROC curve and calculate AUC score using test set.\n",
    "print(\"----ROC----RECEIVER---OPERATOR---CHARACTERSTIC----\\n\")\n",
    "fpr, tpr, thresholds = roc_curve(test_data.spam, base_predicted_proba[:,1])\n",
    "print(\"When prob>threshold => return 1 else return 0.\")\n",
    "print(\"Prob tresholds:\\n\",thresholds)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()\n",
    "print(\"----AUC----AREA---UNDER---CURVE-------------------\\n\")\n",
    "print(roc_auc_score(test_data.spam, base_predicted_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of valid mails classified as spam (FPR): 1.3605%\n"
     ]
    }
   ],
   "source": [
    "#PART B d). What percentage of valid mails is spam?\n",
    "#In other words we are looking for FPR, where positive means spam.\n",
    "ham_mails_as_spam = np.count_nonzero(base_predicted[np.where(test_data.spam==0)]==1)\n",
    "ham_mails = len(base_predicted[np.where(test_data.spam==0)])\n",
    "print(\"Percentage of valid mails classified as spam (FPR): {0:.4%}\".format(ham_mails_as_spam/ham_mails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of spam among mails classified as ham: 1.5280%\n"
     ]
    }
   ],
   "source": [
    "#PART B e). Assuming that only mails classified as ham are put \n",
    "#in our mailbox what percentage of mail in our inbox is spam?\n",
    "\n",
    "spam_mails_as_ham= np.count_nonzero(base_predicted[np.where(test_data.spam==1)]==0)\n",
    "as_ham_mails = np.count_nonzero(base_predicted==0)\n",
    "\n",
    "print(\"Percentage of spam among mails classified as ham: {0:.4%}\".format(spam_mails_as_ham/as_ham_mails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most probable words in spam 1 and ham 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ect</td>\n",
       "      <td>hou</td>\n",
       "      <td>subject</td>\n",
       "      <td>enron</td>\n",
       "      <td>2000</td>\n",
       "      <td>gas</td>\n",
       "      <td>deal</td>\n",
       "      <td>meter</td>\n",
       "      <td>hpl</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject</td>\n",
       "      <td>com</td>\n",
       "      <td>http</td>\n",
       "      <td>company</td>\n",
       "      <td>font</td>\n",
       "      <td>td</td>\n",
       "      <td>www</td>\n",
       "      <td>00</td>\n",
       "      <td>information</td>\n",
       "      <td>statements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1    2        3        4     5    6     7      8            9  \\\n",
       "0      ect  hou  subject    enron  2000  gas  deal  meter          hpl   \n",
       "1  subject  com     http  company  font   td   www     00  information   \n",
       "\n",
       "           10  \n",
       "0          cc  \n",
       "1  statements  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PART C \n",
    "#Find ten most probable and least probable words for each class. \n",
    "n = 10 \n",
    "\n",
    "def word(i):\n",
    "    return vectorizer.get_feature_names()[i]\n",
    "\n",
    "word = np.vectorize(word)\n",
    "most_probable = np.argsort(base_spam_classifier.feature_log_prob_,axis=1)[:,-1:-n-1:-1]\n",
    "most_probable_words = word(most_probable)\n",
    "print(\"10 most probable words in spam 1 and ham 0:\")\n",
    "pd.DataFrame(most_probable_words, index =[0,1], columns=range(1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 least probable words in spam 1 and ham 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyb</td>\n",
       "      <td>lunatics</td>\n",
       "      <td>lunary</td>\n",
       "      <td>lunar</td>\n",
       "      <td>lunacy</td>\n",
       "      <td>lumpish</td>\n",
       "      <td>lummox</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>luminescent</td>\n",
       "      <td>luminance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>replacement</td>\n",
       "      <td>loring</td>\n",
       "      <td>lorio</td>\n",
       "      <td>bolt</td>\n",
       "      <td>loses</td>\n",
       "      <td>bombeck</td>\n",
       "      <td>feeding</td>\n",
       "      <td>feedbacks</td>\n",
       "      <td>bonaire</td>\n",
       "      <td>sixth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2       3      4       5        6        7           8  \\\n",
       "0          hyb  lunatics  lunary  lunar  lunacy  lumpish   lummox  luminosity   \n",
       "1  replacement    loring   lorio   bolt   loses  bombeck  feeding   feedbacks   \n",
       "\n",
       "             9         10  \n",
       "0  luminescent  luminance  \n",
       "1      bonaire      sixth  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_probable = np.argsort(base_spam_classifier.feature_log_prob_,axis=1)[:,:n]\n",
    "least_probable_words = word(least_probable)\n",
    "print(\"10 least probable words in spam 1 and ham 0:\") \n",
    "pd.DataFrame(least_probable_words, index =[0,1], columns=range(1,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART: D\n",
    "#Check the classifier on the remaining datasets data/Enron_2-6. For each set calculate recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "data2 = load_files('enron_spam/data/Enron_2/', encoding='latin-1', shuffle=True, categories=['ham', 'spam'] )\n",
    "data3 = load_files('enron_spam/data/Enron_3/', encoding='latin-1', shuffle=True, categories=['ham', 'spam'] )\n",
    "data4 = load_files('enron_spam/data/Enron_4/', encoding='latin-1', shuffle=True, categories=['ham', 'spam'] )\n",
    "data5 = load_files('enron_spam/data/Enron_5/', encoding='latin-1', shuffle=True, categories=['ham', 'spam'] )\n",
    "data6 = load_files('enron_spam/data/Enron_6/', encoding='latin-1', shuffle=True, categories=['ham', 'spam'] )\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'text': data2['data'], 'spam': data2['target']})\n",
    "df3 = pd.DataFrame({'text': data3['data'], 'spam': data3['target']})\n",
    "df4 = pd.DataFrame({'text': data4['data'], 'spam': data4['target']})\n",
    "df5 = pd.DataFrame({'text': data5['data'], 'spam': data5['target']})\n",
    "df6 = pd.DataFrame({'text': data6['data'], 'spam': data6['target']})\n",
    "\n",
    "dfi=[df2, df3, df4, df5, df6]\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score 1: 0.9085812893699179\n",
      "recall score    1: 0.9431016139354502\n",
      "f1 score        1: 0.9236795613069015\n",
      "precision score 2: 0.9500057060491564\n",
      "recall score    2: 0.9710417315882414\n",
      "f1 score        2: 0.9597455144719241\n",
      "precision score 3: 0.9279634710758599\n",
      "recall score    3: 0.9427719505418172\n",
      "f1 score        3: 0.9350238614063258\n",
      "precision score 4: 0.9408132735954624\n",
      "recall score    4: 0.9680697278911565\n",
      "f1 score        4: 0.9528214326511604\n",
      "precision score 5: 0.9515917046161199\n",
      "recall score    5: 0.9619444444444445\n",
      "f1 score        5: 0.9566128652465617\n"
     ]
    }
   ],
   "source": [
    "#PART B b). Calculate recall and precision scores.\n",
    "for i in range(5):\n",
    "    base_predicted_i = base_spam_classifier.predict(vectorizer.transform(dfi[i].text))\n",
    "    print(\"precision score {}:\".format(i+1), precision_score(dfi[i].spam, base_predicted_i, average='macro'))\n",
    "    print(\"recall score    {}:\".format(i+1), recall_score(dfi[i].spam, base_predicted_i, average='macro'))\n",
    "    print(\"f1 score        {}:\".format(i+1), f1_score(dfi[i].spam, base_predicted_i, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART: E\n",
    "#Combine all sets. Train a new classifier on the combined set, of course after dividing into test and train sets. Redo point B. using this classifier and combined test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'text': data1['data'], 'spam': data1['target']})\n",
    "dframe=[df1, df2, df3, df4, df5, df6]\n",
    "all_sets = pd.concat(dframe)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 57576\n",
    "train_data_e, test_data_e = train_test_split(all_sets, train_size=0.8, test_size=0.2, stratify=all_sets['spam'], random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leangth of the created vocabulary:\n",
      "127621\n",
      "precision score: 0.9855174863477401\n",
      "recall score:    0.985555145572826\n",
      "f1 score:        0.9855350954397932\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenization\n",
    "vectorizer_e = CountVectorizer(stop_words='english')\n",
    "train_spam_score_e = vectorizer_e.fit_transform(train_data_e.text)\n",
    "test_spam_score_e = vectorizer_e.transform(test_data_e.text)\n",
    "\n",
    "#Multinomial Bayes classification\n",
    "base_spam_classifier_e = MultinomialNB()\n",
    "base_spam_classifier_e.fit(train_spam_score_e, train_data_e.spam)\n",
    "\n",
    "base_predicted_e = base_spam_classifier_e.predict(test_spam_score_e)\n",
    "base_predicted_proba_e = base_spam_classifier_e.predict_proba(test_spam_score_e)\n",
    "\n",
    "#Print vocabulaty size\n",
    "print(\"\\nLeangth of the created vocabulary:\")\n",
    "print(len(vectorizer_e.vocabulary_))\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "#------------------------------------REDO B------------------------------------------#\n",
    "#------------------------------------------------------------------------------------#\n",
    "\n",
    "#PART E a).Draw the confusion matrix using plot_confusion_matrix from scikit-learn\n",
    "fig_e, ax_e = plt.subplots(figsize=(6,4))\n",
    "disp_e = plot_confusion_matrix(base_spam_classifier_e, test_spam_score_e, test_data_e.spam, normalize='true', ax=ax_e);\n",
    "\n",
    "#PART E b). Calculate recall and precision scores.\n",
    "print(\"precision score:\", precision_score(test_data_e.spam, base_predicted_e, average='macro'))\n",
    "print(\"recall score:   \", recall_score(test_data_e.spam, base_predicted_e, average='macro'))\n",
    "print(\"f1 score:       \", f1_score(test_data_e.spam, base_predicted_e, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----ROC----RECEIVER---OPERATOR---CHARACTERSTIC----\n",
      "\n",
      "When prob>threshold => return 1 else return 0.\n",
      "Prob tresholds:\n",
      " [2.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 9.99999997e-001 9.99999997e-001\n",
      " 9.99999995e-001 9.99999994e-001 9.99999992e-001 9.99999991e-001\n",
      " 9.99999983e-001 9.99999982e-001 9.99999980e-001 9.99999979e-001\n",
      " 9.99999974e-001 9.99999974e-001 9.99999970e-001 9.99999970e-001\n",
      " 9.99999944e-001 9.99999944e-001 9.99999935e-001 9.99999933e-001\n",
      " 9.99999931e-001 9.99999929e-001 9.99999905e-001 9.99999901e-001\n",
      " 9.99999832e-001 9.99999827e-001 9.99999597e-001 9.99999589e-001\n",
      " 9.99999075e-001 9.99999041e-001 9.99997831e-001 9.99997814e-001\n",
      " 9.99993390e-001 9.99993357e-001 9.99993288e-001 9.99993254e-001\n",
      " 9.99992372e-001 9.99991993e-001 9.99989650e-001 9.99989648e-001\n",
      " 9.99987746e-001 9.99987609e-001 9.99975162e-001 9.99975104e-001\n",
      " 9.99957195e-001 9.99954644e-001 9.99782328e-001 9.99765564e-001\n",
      " 9.99405343e-001 9.99401864e-001 9.98414147e-001 9.98370122e-001\n",
      " 9.97276508e-001 9.97069112e-001 9.96693911e-001 9.96342884e-001\n",
      " 9.96286095e-001 9.95966995e-001 9.94770043e-001 9.94760308e-001\n",
      " 9.93388084e-001 9.93334718e-001 9.90123345e-001 9.89916606e-001\n",
      " 9.82938813e-001 9.82361226e-001 9.71380745e-001 9.67900766e-001\n",
      " 9.57449078e-001 9.55827782e-001 9.53096686e-001 9.52237553e-001\n",
      " 9.15073597e-001 9.14338827e-001 8.92085722e-001 8.84162019e-001\n",
      " 8.30693502e-001 8.29172316e-001 8.11940142e-001 8.07728498e-001\n",
      " 8.00424075e-001 7.88524129e-001 7.85948910e-001 7.43993821e-001\n",
      " 7.32417421e-001 5.25782118e-001 5.17903791e-001 5.15389258e-001\n",
      " 4.69089529e-001 4.29291153e-001 3.87782077e-001 3.59263928e-001\n",
      " 3.47500969e-001 3.32523228e-001 3.21286372e-001 2.97019268e-001\n",
      " 2.85601398e-001 1.93518586e-001 1.91213729e-001 1.67785654e-001\n",
      " 1.62974719e-001 1.53675779e-001 1.38820880e-001 1.04669046e-001\n",
      " 9.42430432e-002 7.45270830e-002 5.62355300e-002 5.47760677e-002\n",
      " 5.41528482e-002 5.26296062e-002 4.74196149e-002 2.76843432e-002\n",
      " 2.48712303e-002 1.77664867e-002 1.63396226e-002 1.20028770e-002\n",
      " 8.55731536e-003 6.57151202e-003 6.35293901e-003 5.29115187e-003\n",
      " 5.15844044e-003 1.44514257e-004 1.39334592e-004 3.68053081e-005\n",
      " 3.10130654e-005 1.37167144e-005 1.32438066e-005 5.99890135e-008\n",
      " 5.67178668e-008 1.65059647e-008 1.55324957e-008 1.50873102e-011\n",
      " 1.47228300e-011 2.58359322e-015 2.51881589e-015 7.82375493e-016\n",
      " 7.38917626e-016 2.09003544e-017 1.77082032e-017 1.18115801e-017\n",
      " 1.17591885e-017 7.67917731e-018 7.61443073e-018 1.30689448e-018\n",
      " 1.30029641e-018 2.52781555e-019 2.50514649e-019 7.91636172e-020\n",
      " 7.43018908e-020 6.33102291e-023 6.29872523e-023 3.19236957e-026\n",
      " 2.67121932e-026 1.00060032e-027 9.35233198e-028 1.35389935e-035\n",
      " 1.17004912e-035 4.23840323e-036 4.06111887e-036 2.87665295e-036\n",
      " 2.86450851e-036 1.49582502e-036 1.40796346e-036 1.36120683e-036\n",
      " 1.06333964e-036 1.05305615e-036 1.04161132e-036 1.01982982e-036\n",
      " 8.51367688e-037 8.09113684e-037 5.05260880e-037 4.20316950e-037\n",
      " 1.48883778e-037 1.26517879e-037 1.12639079e-037 9.75224470e-038\n",
      " 6.87361256e-039 6.69304333e-039 6.31024199e-055 5.39453262e-055\n",
      " 1.60107821e-058 1.46533364e-058 2.98109470e-060 2.88904253e-060\n",
      " 2.22260624e-069 1.35663808e-069 4.33952571e-070 3.79869047e-070\n",
      " 4.39256173e-075 4.32781337e-075 1.22363605e-077 8.35140628e-078\n",
      " 1.94106779e-091 1.30160751e-091 3.58992686e-117 3.34658953e-117\n",
      " 1.62875548e-151 1.56950945e-151 2.14448164e-169 8.35546321e-170\n",
      " 3.60020620e-176 3.48056481e-176 2.29114228e-189 1.34024225e-189\n",
      " 4.94065646e-323 0.00000000e+000]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASy0lEQVR4nO3dbYxcV33H8e9/7TjPT403IbKd2KFOGyulDdqmtEglKKFyUtVWJYpsKWqpIiJoQ1+AKqWiSlF4VVCLiuQWrBZRqEgIvAALGUUCQmkRpt4oEPLQ0MUkeJsIL2maJgQ/rOffF3fWOztzd/euPbuzZ/z9SNbszD0z8z+e9S8n5545NzITSVL5RgZdgCSpPwx0SRoSBrokDQkDXZKGhIEuSUNi7aDeeP369bl58+ZBvb0kFenRRx/9aWaO1h0bWKBv3ryZ8fHxQb29JBUpIp6b75hTLpI0JAx0SRoSBrokDQkDXZKGhIEuSUNi0UCPiE9GxJGIeGKe4xERH4uIiYh4PCLe2P8yJUmLaTJC/xSwfYHjtwNb23/uBv7hzMuSJC3VouvQM/ObEbF5gSY7gU9ntQ/vgYi4LCKuzswX+lRj32UmrZy9bbW3EG5lku37rQQSfn7iJD87Ps3sLsPZfo2Znzh1LDuP1TzGAu1nXnlmO+MEjp44yStHpzlnTdT0Yb6+zfN4/cPMt33y/O3nObDAs5Ze03zt+/X6S98yuh81nWwlh1/6OZeef07f6jqd2hZ6TvW8pb/Xmbzf/M9ZHfWf7nst9MRbb7iKX9102ULPPi39+GLRBuBwx/3J9mM9gR4Rd1ON4rnmmmv68NazMpPPHTzMx//1h2z6hQs42UpOtpJWVrdP/Pf/ccVF65huJVOvHOvre0tSnegdiwFw5SXnrdpAryu59j9NmbkX2AswNjbWlytrnDjZ4j3/8ihfffrIqceeffE1xq69nJGRYO3ICOeuDX59y+WcOJm8fvRC1o6M8Oqxaa5bfyEREBGMRBABIwEj7U9h5na61eKqS84j2vdnOhwB0b4388F1HmPeY9HVrrNNnGoYwPTJZPTic2v7Pt8vS9R+JPO3n89SX3/B5/Sp1vneef6+Lf3vYv73mOe1llDTSASXzDNCP926Tqe2xd9r6Z/xYvr5+1Q9b6H3WuA1F3ze0l9vNelHoE8CmzrubwSe78PrNrL/+y+cCvPbbriKv9v1a1x47sB2NJCkgelH8u0D7omIB4HfAF5eyfnzHx55FYCvv/8tXDd60Uq9rSStOosGekQ8ANwCrI+ISeCvgHMAMvPjwH7gDmACeA344+Uqts4DB6vp+6svPX8l31aSVp0mq1x2L3I8gT/tW0VLNHOC8/x1awZVgiStCkV/U/Rkqzqveu0VFwy4EkkavKID/ev/WZ0MfesvXTngSiRp8IoO9H//rykAfv+mDQOuRJIGr+hA//ahFwG44epLBlyJJA1e0YHenkJn3dqiuyFJfVF0Ek4ceZVfft3Fgy5DklaFYgP96ImTALzeLxNJElBwoL/02nEAR+iS1FZsoP/sWDVCX2ijI0k6mxQb6DMuv3DdoEuQpFWh+ECXJFUMdEkaEga6JA0JA12ShkSxgf7ciz8bdAmStKoUG+jPv3wUgPPPcR90SYKCA/1HU9UI/cYNbswlSVBwoM9chPt1l5w32EIkaZUoNtCfe/E1AGIm2SXpLFdsoF9+wTlc4HVEJemUYgMd4DL3cZGkU4oOdEnSLANdkoZEsYH++UcnmZ65Bp0kqdxAv/i8tRx55digy5CkVaPIQD8+3eKVo9P81uuvGHQpkrRqFBnoP/jJKwBccdG5A65EklaPIgN9xu+94epBlyBJq0bRgS5JmmWgS9KQMNAlaUg0CvSI2B4Rz0TERETcW3P8moh4JCIei4jHI+KO/pcqSVrIooEeEWuAPcDtwDZgd0Rs62r2l8BDmXkTsAv4+34XKklaWJMR+s3ARGYeyszjwIPAzq42CcxcaeJS4Pn+lShJaqJJoG8ADnfcn2w/1umDwJ0RMQnsB95b90IRcXdEjEfE+NTU1GmUK0maT5NAr7uCRPcmKruBT2XmRuAO4DMR0fPambk3M8cyc2x0dHTp1UqS5tUk0CeBTR33N9I7pXIX8BBAZn4bOA9Y348CJUnNNAn0g8DWiNgSEeuoTnru62rzY+BWgIi4gSrQnVORpBW0aKBn5jRwD/Aw8DTVapYnI+L+iNjRbvZ+4F0R8T3gAeCdmenetpK0gtY2aZSZ+6lOdnY+dl/Hz08Bb+5vaZKkpfCbopI0JAx0SRoSBrokDQkDXZKGhIEuSUOiyEB3QaQk9Soy0H/66jHAa4pKUqciA/3YdAuA889ZM+BKJGn1KDLQZ76EOlJk9ZK0PIqMxFZ7Dn0k6jaClKSzU6GB3h6hm+eSdErRgR6O0CXplKID3SkXSZpVZqBXi1yccpGkDmUGuiN0SepRZKDPfFPUPJekWUUGuiN0SepVaKBXtwa6JM0qNNBdhy5J3YoM9Nmv/pvokjSjyEB3ykWSehUa6E65SFK3QgO9uvWr/5I0q8hAT0foktSjyEB3Hbok9So00KtbA12SZhUa6DPb5w64EElaRYoM9HSELkk9igz0VsuTopLUrcxAd4QuST0aBXpEbI+IZyJiIiLunafNOyLiqYh4MiI+298y53IOXZJ6rV2sQUSsAfYAbwMmgYMRsS8zn+posxX4C+DNmflSRFy5XAVDtQ49wi8WSVKnJiP0m4GJzDyUmceBB4GdXW3eBezJzJcAMvNIf8ucq5VOt0hStyaBvgE43HF/sv1Yp+uB6yPiWxFxICK2171QRNwdEeMRMT41NXV6FVNNuXhCVJLmahLoddGZXffXAluBW4DdwD9GxGU9T8rcm5ljmTk2Ojq61FpPaaXTLZLUrUmgTwKbOu5vBJ6vafOlzDyRmT8CnqEK+GWRjtAlqUeTQD8IbI2ILRGxDtgF7Otq80XgrQARsZ5qCuZQPwvtVE25mOiS1GnRQM/MaeAe4GHgaeChzHwyIu6PiB3tZg8DL0bEU8AjwJ9n5ovLVbQnRSWp16LLFgEycz+wv+ux+zp+TuB97T/LrtVetihJmlXkN0XTEbok9Sgy0F22KEm9Cg50E12SOhUa6K5Dl6RuRQa669AlqVeRgd5qeVJUkrqVGeiO0CWpR6GB7hy6JHUrMtAzk5EiK5ek5VNkLLpsUZJ6FRronhSVpG6FBrp7uUhStyID3b1cJKlXkYHuskVJ6lVwoJvoktSp0EB3HbokdSsy0N3LRZJ6FRnoLluUpF6FBrojdEnqVmigO4cuSd2KDHTn0CWpV5GB7rJFSepVZqB7gQtJ6lFmoLuXiyT1KDLQ3ctFknoVGegnvcCFJPUoMhY9KSpJvQoNdNehS1K3IgPddeiS1KvIQHfKRZJ6lRnoLRyhS1KXRoEeEdsj4pmImIiIexdo9/aIyIgY61+JvRyhS1KvRQM9ItYAe4DbgW3A7ojYVtPuYuDPgO/0u8hurkOXpF5NRug3AxOZeSgzjwMPAjtr2n0I+DBwtI/11Wq5Dl2SejSJxQ3A4Y77k+3HTomIm4BNmfnlhV4oIu6OiPGIGJ+amlpysTOqr/47QpekTk0CvS4589TBiBHgo8D7F3uhzNybmWOZOTY6Otq8yp7XccpFkro1CfRJYFPH/Y3A8x33LwZuBL4REc8CbwL2LeeJUa9YJEm9mgT6QWBrRGyJiHXALmDfzMHMfDkz12fm5szcDBwAdmTm+LJUjNcUlaQ6iwZ6Zk4D9wAPA08DD2XmkxFxf0TsWO4C67h9riT1WtukUWbuB/Z3PXbfPG1vOfOyFqvHEbokdSty8Z9z6JLUq+BAN9ElqVOhge72uZLUrchAd/tcSepVZKC7bFGSehUa6I7QJalbmYHeci8XSepWZKC7Dl2SehUZ6E65SFKvQgMdRkx0SZqj0EB3LxdJ6lZkoDuHLkm9igx059AlqVfBgW6iS1KnQgPdvVwkqVtxgZ5ZXc7UKRdJmqu4QG+1L0/tlIskzVVgoDtCl6Q6xQa6c+iSNFdxgZ5OuUhSreIC3SkXSapXYKBXt47QJWmuAgN9Zg59wIVI0ipTXKBnq7p1hC5JcxUX6M6hS1K9cgPdRJekOQoM9OrWdeiSNFdxge5eLpJUr7hAd9miJNUrMNAdoUtSnUaBHhHbI+KZiJiIiHtrjr8vIp6KiMcj4msRcW3/S624l4sk1Vs00CNiDbAHuB3YBuyOiG1dzR4DxjLzDcAXgA/3u9AZ7uUiSfWajNBvBiYy81BmHgceBHZ2NsjMRzLztfbdA8DG/pY5yykXSarXJNA3AIc77k+2H5vPXcBX6g5ExN0RMR4R41NTU82r7OBJUUmq1yTQ65IzaxtG3AmMAR+pO56ZezNzLDPHRkdHm1fZwb1cJKne2gZtJoFNHfc3As93N4qI24APAG/JzGP9Ka/X7Dp0E12SOjUZoR8EtkbElohYB+wC9nU2iIibgE8AOzLzSP/LnOWUiyTVWzTQM3MauAd4GHgaeCgzn4yI+yNiR7vZR4CLgM9HxHcjYt88L3fGTrY8KSpJdZpMuZCZ+4H9XY/d1/HzbX2ua16uQ5ekesV9U3R2Hfpg65Ck1aa4QG95UlSSahUY6NXtGofokjRHgYHuOnRJqlNcoLsOXZLqFRforkOXpHrlBbrr0CWpVnmB7jVFJalWcYHuNUUlqV5xgX5qDt1El6Q5Cgx0R+iSVKfYQHcOXZLmKi7QvaaoJNUrLtCdcpGkegUGenXrCF2S5iow0N3LRZLqFBfo7uUiSfWKC3SnXCSpXoGB7klRSapTYKBXt65Dl6S5igt093KRpHrFBbrXFJWkeuUFequ6NdAlaa7yAt116JJUq7hAT7fPlaRaxQW6yxYlqV6BgV7dOocuSXMVGOjOoUtSneIC3b1cJKlecYHulIsk1Ssw0D0pKkl1GgV6RGyPiGciYiIi7q05fm5EfK59/DsRsbnfhc5wLxdJqrdooEfEGmAPcDuwDdgdEdu6mt0FvJSZvwh8FPjrfhc6w71cJKlekxH6zcBEZh7KzOPAg8DOrjY7gX9u//wF4NZYpiG0e7lIUr0mgb4BONxxf7L9WG2bzJwGXgau6H6hiLg7IsYjYnxqauq0Ct6y/iJ+91euZo1DdEmaY22DNnXJmafRhszcC+wFGBsb6znexNu2XcXbtl11Ok+VpKHWZIQ+CWzquL8ReH6+NhGxFrgU+J9+FChJaqZJoB8EtkbElohYB+wC9nW12Qf8UfvntwNfz5mzl5KkFbHolEtmTkfEPcDDwBrgk5n5ZETcD4xn5j7gn4DPRMQE1ch813IWLUnq1WQOnczcD+zveuy+jp+PAn/Q39IkSUtR3DdFJUn1DHRJGhIGuiQNCQNdkoZEDGp1YURMAc+d5tPXAz/tYzklsM9nB/t8djiTPl+bmaN1BwYW6GciIsYzc2zQdawk+3x2sM9nh+Xqs1MukjQkDHRJGhKlBvreQRcwAPb57GCfzw7L0uci59AlSb1KHaFLkroY6JI0JFZ1oK+mi1OvlAZ9fl9EPBURj0fE1yLi2kHU2U+L9bmj3dsjIiOi+CVuTfocEe9of9ZPRsRnV7rGfmvwu31NRDwSEY+1f7/vGESd/RIRn4yIIxHxxDzHIyI+1v77eDwi3njGb5qZq/IP1Va9PwSuA9YB3wO2dbX5E+Dj7Z93AZ8bdN0r0Oe3Ahe0f37P2dDndruLgW8CB4CxQde9Ap/zVuAx4PL2/SsHXfcK9Hkv8J72z9uAZwdd9xn2+beBNwJPzHP8DuArVFd8exPwnTN9z9U8Ql9VF6deIYv2OTMfyczX2ncPUF1BqmRNPmeADwEfBo6uZHHLpEmf3wXsycyXADLzyArX2G9N+pzAJe2fL6X3ymhFycxvsvCV23YCn87KAeCyiLj6TN5zNQd63y5OXZAmfe50F9V/4Uu2aJ8j4iZgU2Z+eSULW0ZNPufrgesj4lsRcSAitq9YdcujSZ8/CNwZEZNU119478qUNjBL/fe+qEYXuBiQvl2cuiCN+xMRdwJjwFuWtaLlt2CfI2IE+CjwzpUqaAU0+ZzXUk273EL1f2H/FhE3Zub/LnNty6VJn3cDn8rMv4mI36S6CtqNmdla/vIGou/5tZpH6Gfjxamb9JmIuA34ALAjM4+tUG3LZbE+XwzcCHwjIp6lmmvcV/iJ0aa/21/KzBOZ+SPgGaqAL1WTPt8FPASQmd8GzqPaxGpYNfr3vhSrOdDPxotTL9rn9vTDJ6jCvPR5VVikz5n5cmauz8zNmbmZ6rzBjswcH0y5fdHkd/uLVCfAiYj1VFMwh1a0yv5q0ucfA7cCRMQNVIE+taJVrqx9wB+2V7u8CXg5M184o1cc9JngRc4S3wH8gOrs+Afaj91P9Q8aqg/888AE8B/AdYOueQX6/FXgJ8B323/2Dbrm5e5zV9tvUPgql4afcwB/CzwFfB/YNeiaV6DP24BvUa2A+S7wO4Ou+Qz7+wDwAnCCajR+F/Bu4N0dn/Ge9t/H9/vxe+1X/yVpSKzmKRdJ0hIY6JI0JAx0SRoSBrokDQkDXZKGhIEuSUPCQJekIfH/S81NQnxwgukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----AUC----AREA---UNDER---CURVE-------------------\n",
      "\n",
      "0.9961490427652022\n",
      "Percentage of valid mails classified as spam (FPR): 1%\n",
      "Percentage of spam among mails classified as ham: 2%\n"
     ]
    }
   ],
   "source": [
    "#PART E c). Draw ROC curve and calculate AUC score using test set.\n",
    "print(\"----ROC----RECEIVER---OPERATOR---CHARACTERSTIC----\\n\")\n",
    "fpr_e, tpr_e, thresholds_e = roc_curve(test_data_e.spam, base_predicted_proba_e[:,1])\n",
    "print(\"When prob>threshold => return 1 else return 0.\")\n",
    "print(\"Prob tresholds:\\n\",thresholds_e)\n",
    "plt.plot(fpr_e,tpr_e)\n",
    "plt.show()\n",
    "print(\"----AUC----AREA---UNDER---CURVE-------------------\\n\")\n",
    "print(roc_auc_score(test_data_e.spam, base_predicted_proba_e[:,1]))\n",
    "\n",
    "#PART E d). What percentage of valid mails is spam?\n",
    "#In other words we are looking for FPR, where positive means spam.\n",
    "ham_mails_as_spam_e = np.count_nonzero(base_predicted_e[np.where(test_data_e.spam==0)]==1)\n",
    "ham_mails_e = len(base_predicted_e[np.where(test_data_e.spam==0)])\n",
    "print(\"Percentage of valid mails classified as spam (FPR): {0:.0%}\".format(ham_mails_as_spam_e/ham_mails_e))\n",
    "\n",
    "#PART E e). Assuming that only mails classified as ham are put \n",
    "#in our mailbox what percentage of mail in our inbox is spam?\n",
    "\n",
    "spam_mails_as_ham_e= np.count_nonzero(base_predicted_e[np.where(test_data_e.spam==1)]==0)\n",
    "as_ham_mails_e = np.count_nonzero(base_predicted_e==0)\n",
    "\n",
    "print(\"Percentage of spam among mails classified as ham: {0:.0%}\".format(spam_mails_as_ham_e/as_ham_mails_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART: F\n",
    "#Assumimg that we want to keep the frequency \n",
    "#of misclassified ham mails below 5 per mille,\n",
    "#what would be the percentage of spam in our inbox?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "0.004911220249338874\n"
     ]
    }
   ],
   "source": [
    "distance=abs(np.subtract(fpr_e,0.005))\n",
    "index=np.flatnonzero(distance == distance.min())[0]\n",
    "print(index)\n",
    "print(fpr_e[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here I had a problem with a clear interpretation of the question.\n",
    "I am not sure whether we are expected to find the percentage of spam that (ends up!) in our inbox\n",
    "containing ham mails exclusively\n",
    "\n",
    "(procent całego spamu lądującego w skrzynce z ham: opcja 1)\n",
    "\n",
    "\n",
    "\n",
    "or maybe the percentage of spam in our inbox\n",
    "\n",
    "(procent jaki zajmuje spam w naszej skrzynce z ham: opcja 2).\n",
    "\n",
    " W przypadku opcji 1 wzór odpowiadający odpowiedzi będzie miał postać \n",
    "(1-tpr).\n",
    "\n",
    "\n",
    " W przypadku opcji 2 wzór odpowiadający odpowiedzi to (true_spam as ham)/(classified_as_ham).\n",
    " \n",
    " W związku z tymi wątpliwościami interpretacyjnymi wykonałem obie rzeczy!\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procent całego spamu jaki ląduje w naszej skrzynce to 16.0175%.\n"
     ]
    }
   ],
   "source": [
    "#opcja 1\n",
    "print(\"Procent całego spamu jaki ląduje w naszej skrzynce to {0:.4%}.\".format(1-tpr_e[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procent jaki zajmuje spam w skrzynce, do której wpadają tylko maile zaklasyfikowane jako ham: 14.3136%.\n"
     ]
    }
   ],
   "source": [
    "#opcja 2\n",
    "#Zauważmy, że (1-tpr)=(ture_spam as ham)/(true_spam)\n",
    "#Wystarczy więc wziąć (1-tpr)*(true_spam)/(classified_as_ham_mails)\n",
    "classified_as_ham_mails =np.sum(np.where(base_predicted_proba_e[:,1] < thresholds_e[index], 1, 0))\n",
    "true_spam = len(np.where(test_data_e.spam==1)[0])\n",
    "\n",
    "print(\"Procent jaki zajmuje spam w skrzynce, do której wpadają \\\n",
    "tylko maile zaklasyfikowane jako ham: {0:.4%}.\".format((1-tpr_e[index])*(true_spam/classified_as_ham_mails)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
